# -*- coding: utf-8 -*-
"""POLYCYSTIC OVARY SYNDROME (PCOS) DIAGNOSIS USING MACHINE LEARNING.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IPq7LzpL1JiEHu9NhxR2z_FGHMBVdZ1y

### **<p style="background-color:teal;font-family:newtimeroman;color:white;font-size:120%;text-align:center;border-radius:20px 60px;">POLYCYSTIC OVARY SYNDROME (PCOS) DIAGNOSIS USING MACHINE LEARNING</p>**

**<span style="color:teal;"> Polycystic Ovary Syndrome (PCOS) </span>** is a hormonal condition that affects many women of reproductive age. Women with PCOS may have irregular or prolonged menstrual cycles, as well as high levels of the male hormone androgen. The ovaries may produce a large number of tiny collections of fluid (follicles) and fail to release eggs on a regular basis. (Source: https://www.mayoclinic.org/diseases-conditions/pcos/symptoms-causes/syc-20353439#:~:text=Polycystic%20ovary%20syndrome%20(PCOS)%20is,fail%20to%20regularly%20release%20eggs)

The high prevalence of PCOS (12.6%) among Malaysian women could indicate the emergence of a public health problem in the country.

The following are some of the most common PCOS symptoms:

1) Periods that are irregular or nonexistent.

2) Having trouble getting pregnant (because of irregular ovulation or failure to ovulate)

3) Hair growth that is excessive which  typically on the face, chest, back, or buttocks.

4) gaining weight

5) Hair thinning and hair loss on the head

6) Acne or greasy skin

In this project, we have proposed a Random Forest Classifier as the best model for PCOS Diagnosis.

# <p style="background-color:teal;font-family:newtimeroman;color:white;text-align:center;font-size:120%;border-radius:20px 60px;">Table Of Contents</p>

* **Importing Necessary Libraries**
* **Read In and Explore the Data**
* **Data Cleaning**
* **EDA and Data Visualization**
* **Best Model: Random Forest Classifier**
* **Discussion**
* **Impact**
* **Conclusion**

# <p style="background-color:teal;font-family:newtimeroman;color:white;font-size:120%;text-align:center;border-radius:20px 60px;">Importing Necessary Libraries</p>

Firstly, we need to import necessary libraries such as numpy, pandas, and seaborn.
"""

# This Python 3 environment comes with many helpful analytics libraries installed
# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python
# For example, here's several helpful packages to load

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)

# Input data files are available in the read-only "../input/" directory
# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using "Save & Run All" 
# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session

#Importing all the libraries that we use in this project
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report

"""Next, we upload the dataset"""

from google.colab import files
uploaded = files.upload()

from google.colab import files
uploaded = files.upload()

""" # <p style="background-color:teal;font-family:newtimeroman;color:white;font-size:120%;text-align:center;border-radius:20px 60px;">Read In and Explore the Data</p>
 
 **About the data:**

* This dataset contains all physical and clinical parameters to determine PCOS and infertility related issues. There are a total of 44 parameters. 

* This data is collected from 10 different hospitals across Kerala, India.

* The unit used is feet to cm

* Blood pressure entered as systolic and diastolic separately

* RBS means Random glucose test

* Beta-HCG cases are mentioned as Case I and II

* Blood Group indications: A+ = 11, A- = 12, B+ = 13, B- = 14, O+ =15, O- = 16, AB+ =17, AB- = 18

"""

#Loading data into the kernels 

file_path_with_infertility="../input/polycystic-ovary-syndrome-pcos/PCOS_infertility.csv"
file_path_without_infertility="../input/polycystic-ovary-syndrome-pcos/PCOS_data_without_infertility.xlsx"

PCOS_inf = pd.read_csv(file_path_with_infertility)
PCOS_woinf = pd.read_excel(file_path_without_infertility, sheet_name="Full_new")

"""# <p style="background-color:teal;font-family:newtimeroman;color:white;font-size:120%;text-align:center;border-radius:20px 60px;">Data Cleaning</p>

**Steps involved in Data Cleaning:**

* Merging the two files that are sorted into two based on patients with infertility and without infertility

* Dropping the repeated features
 
* Encoding categorical variables (dtype objects)

* Dealing with missing values

**<span style="color:teal;"> Merging the two files as per patient file no. and dropping the repeated features</span>**
"""

#Merging the two files as per patient file no. 
#The files were sorted into two based on patients with infertility and without infertility
data = pd.merge(PCOS_woinf,PCOS_inf, on='Patient File No.', suffixes={'','_y'},how='left')

#Dropping the repeated features after merging
data =data.drop(['Unnamed: 44', 'Sl. No_y', 'PCOS (Y/N)_y', '  I   beta-HCG(mIU/mL)_y',
       'II    beta-HCG(mIU/mL)_y', 'AMH(ng/mL)_y'], axis=1)

#Taking a look at the dataset
data.head()

"""Everything looks alright we can work with this.

We have a dataset of shape 5 rows × 44 columns.

Let's head up to the next step and have a further look at the data.
"""

data.info()

"""**<span style="color:teal;"> Encoding categorical variables (dtype objects)</span>**"""

#Having a look at the data with dtype objects

data["AMH(ng/mL)"].head()

#Similarly

data["II    beta-HCG(mIU/mL)"].head()

"""After having a look at this info we may conclude that:

* Some numeric data are saved as strings.
* There are some missing values. Namely, Marriage Status (Yrs)& Fast food (Y/N)
"""

#Dealing with categorical values.
#In this database the type objects are numeric values saved as strings.
#So I am just converting it into a numeric value.

data["AMH(ng/mL)"] = pd.to_numeric(data["AMH(ng/mL)"], errors='coerce')
data["II    beta-HCG(mIU/mL)"] = pd.to_numeric(data["II    beta-HCG(mIU/mL)"], errors='coerce')

#Dealing with missing values. 
#Filling NA values with the median of that feature.

data['Marraige Status (Yrs)'].fillna(data['Marraige Status (Yrs)'].median(),inplace=True)
data['II    beta-HCG(mIU/mL)'].fillna(data['II    beta-HCG(mIU/mL)'].median(),inplace=True)
data['AMH(ng/mL)'].fillna(data['AMH(ng/mL)'].median(),inplace=True)
data['Fast food (Y/N)'].fillna(data['Fast food (Y/N)'].median(),inplace=True)

#Clearing up the extra space in the column names (optional)

data.columns = [col.strip() for col in data.columns]

""" # <p style="background-color:teal;font-family:newtimeroman;color:white;font-size:120%;text-align:center;border-radius:20px 60px;">Exploratory Data Analysis and Data Visualization</p>


**Steps involved in EDA**
* Feature selection based on the correlation factor 
* Patterns Of Length Of The Menstrual Cycle
* Patterns Of BMI 
* Patterns Of Irregularity In Mensuration 
* Number of Follicles
* Some Miscellaneous EDA


**<span style="color:teal;"> Let's explore features </span>**
"""

#Examaning a correlation matrix of all the features 

corrmat = data.corr()
plt.subplots(figsize=(18,18))
sns.heatmap(corrmat,cmap="Pastel1", square=True);

# Having a look at some basic statistical details.

data.describe()

#Added in the recent update. 
#This came upon evaluating the dataset some obvious outliers I am not explaining the process I used. 
#Dropping the outliers. 

data = data[(data["BP _Diastolic (mmHg)"]>20)]
data = data[(data["AMH(ng/mL)"]<40)]
data = data[(data["BP _Systolic (mmHg)"]>20)]
data = data[(data["Endometrium (mm)"]>0)]
data = data[(data["Avg. F size (R) (mm)"]>0)]
data = data[(data["Avg. F size (R) (mm)"]>0)]
data = data[(data["RBS(mg/dl)"]<200)]
data = data[(data["PRG(ng/mL)"]<20)]
data = data[(data["Pulse rate(bpm)"]>20)]
data = data[(data["FSH(mIU/mL)"]<4000)]
data = data[(data["LH(mIU/mL)"]<1500)]
data = data[(data["Cycle(R/I)"]<4.5)]

data.shape

#Examaning a correlation matrix of all the features 

corrmat = data.corr()
plt.subplots(figsize=(18,18))
sns.heatmap(corrmat,cmap="Pastel1", square=True);

#How all the features correlate with the PCOS 

corrmat["PCOS (Y/N)"].sort_values(ascending=False)

#Having a look at features bearing significant correlation

plt.figure(figsize=(12,12))
k = 12 #number of variables with positive for heatmap
l = 3 #number of variables with negative for heatmap
cols_p = corrmat.nlargest(k, "PCOS (Y/N)")["PCOS (Y/N)"].index 
cols_n = corrmat.nsmallest(l, "PCOS (Y/N)")["PCOS (Y/N)"].index
cols = cols_p.append(cols_n) 

cm = np.corrcoef(data[cols].values.T)
sns.set(font_scale=1.25)
hm = sns.heatmap(cm, cbar=True,cmap="Pastel1", annot=True, square=True, fmt='.2f', annot_kws={'size': 10}, yticklabels=cols.values, xticklabels=cols.values)
plt.show()

""" **<span style="color:teal;"> Patterns Of Length Of The Menstrual Cycle </span>**"""

# Length of menstrual phase in PCOS vs normal 
color = ["teal", "plum"]
fig=sns.lmplot(data=data,x="Age (yrs)",y="Cycle length(days)", hue="PCOS (Y/N)",palette=color)
plt.show(fig)

"""The length of the menstrual phase is overall consistent over different ages for normal cases. Whereas in the case of PCOD the length increased with age. 

 **<span style="color:teal;"> Patterns Of BMI </span>**
"""

# Pattern of weight gain (BMI) over years in PCOS and Normal. 
fig= sns.lmplot(data =data,x="Age (yrs)",y="BMI", hue="PCOS (Y/N)", palette= color )
plt.show(fig)

"""Body mass index (BMI) is showing consistency for normal cases. Whereas for PCOS the BMI increases with age.

 **<span style="color:teal;"> Patterns Of Irregularity In Mensuration  </span>**

*There is no clarity on what this feature and its values indicate but, *

**Apparently in the feature "Cycle(R/I)" value:**

**4** indicates irregular menstrual cycle 

**2** indicates a regular menstrual cycle
"""

# cycle IR wrt age 
sns.lmplot(data =data,x="Age (yrs)",y="Cycle(R/I)", hue="PCOS (Y/N)",palette=color)
plt.show()

"""The menstrual cycle becomes more regular for normal cases with age. Whereas, for PCOS the irregularity increases with age.

 **<span style="color:teal;"> Number Of Follicles </span>**
"""

# Distribution of follicles in both ovaries. 
sns.lmplot(data =data,x='Follicle No. (R)',y='Follicle No. (L)', hue="PCOS (Y/N)",palette=color)
plt.show()

"""The distribution of follicles in both ovaries Left and Right are not equal for women with PCOS in comparison with the "Normal" patient. 
Thia is curious let's exlore it with boxen plot. 
"""

features = ["Follicle No. (L)","Follicle No. (R)"]
for i in features:
    sns.swarmplot(x=data["PCOS (Y/N)"], y=data[i], color="black", alpha=0.5 )
    sns.boxenplot(x=data["PCOS (Y/N)"], y=data[i], palette=color)
    plt.show()

"""The number of follicles in women with PCOS is higher, as expected. And are unequal as well. 
 
**<span style="color:teal;"> Some Miscellaneous EDA </span>**
"""

features = ["Age (yrs)","Weight (Kg)", "BMI", "Hb(g/dl)", "Cycle length(days)","Endometrium (mm)" ]
for i in features:
    sns.swarmplot(x=data["PCOS (Y/N)"], y=data[i], color="black", alpha=0.5 )
    sns.boxenplot(x=data["PCOS (Y/N)"], y=data[i], palette=color)
    plt.show()

""" # <p style="background-color:teal;font-family:newtimeroman;color:white;font-size:120%;text-align:center;border-radius:20px 60px;"> Best Model : Random Forest Classifier</p>

**Steps involved in Model Building:**

* Assigning values to features as X and target as y
* Split test and training sets
* Fitting a vanilla model as the base Random Forest model
* Hyperparameter tuning using GridSearch CV
* Fitting the final model 
* Evaluating the confusion matrix
* Evaluating the classification report
"""

#Assigning the features (X)and target(y)

X=data.drop(["PCOS (Y/N)","Sl. No","Patient File No."],axis = 1) #droping out index from features too
y=data["PCOS (Y/N)"]

#Splitting the data into test and training sets

X_train,X_test, y_train, y_test = train_test_split(X,y, test_size=0.3)

""" **<span style="color:teal;"> Fitting the Model </span>**
 
Fitting a rather vanilla model as base model 
"""

#Fitting the RandomForestClassifier to the training set

rfc = RandomForestClassifier()
rfc.fit(X_train, y_train)

#Making prediction and checking the test set

pred_rfc = rfc.predict(X_test)
accuracy = accuracy_score(y_test, pred_rfc)
print(accuracy)

#Building a dictionary with list of optional values that will be analysed by GridSearch CV

parameters = { 
    'n_estimators': [100,150, 200,500,700],
    'max_features': ['auto', 'sqrt', 'log2'],
    'max_depth' : [4,5,6,7,8,9,10,12],
    'criterion' :['gini', 'entropy'],
    'n_jobs':[-1,1,None]
}

#Fitting the trainingset to find parameters with best accuracy

CV_rfc = GridSearchCV(estimator=rfc, param_grid=parameters, cv= 7)
CV_rfc.fit(X_train, y_train)

#Getting the outcome of gridsearch

CV_rfc.best_params_

#Fitting the model with selected parameters

rfc1=RandomForestClassifier(**CV_rfc.best_params_)
rfc1.fit(X_train, y_train)

#Testing the Model on test set

predictions=rfc1.predict(X_test)
acccuracy_final = accuracy_score(y_test,predictions)

acccuracy_final

"""**<span style="color:teal;"> Classification Report & Confusion Matrix </span>**"""

classi_report = classification_report(y_test, predictions)
print(classi_report)

# cofusion matrix
plt.subplots(figsize=(15,5))
cf_matrix = confusion_matrix(y_test, predictions)
sns.heatmap(cf_matrix/np.sum(cf_matrix), annot = True, annot_kws = {'size':15}, cmap = 'Pastel1')

"""**<span style="color:teal;"> Discussion**

In here, we fitting a vanilla model as the base Random Forest model. When we fitting the Random Forest Classifier to the training set because we want to make a prediction and checking the test set, we got an accuracy value of 0.8987341772151899. Then, when we fitting the model with selected parameters to test the Model on test set, we got a final accuracy which is 0.9050632911392406.

Thus, the final model accuracy is 0.90 which means Random Forest model is the most accurate.

**<span style="color:teal;"> Impact**

Machine Learning is critical in dealing with large amounts of data. Machine learning may aid in the introduction of wearables, smartphones, and other gadgets that are useful in monitoring and tracking a patient's status by introducing an accurate prediction model. Future research could lead to it being used as an early diagnosis tool, as well as a meal recommendation tool and an AI health advisor.

**<span style="color:teal;"> Conclusion**

PCOS (polycystic ovarian syndrome) is a hormonal condition that affects many women of reproductive age. Women with PCOS may have irregular or extended menstrual cycles, as well as high levels of the male hormone androgen.

The illness is one of the most frequent among the world's population, and the number of cases is on the rise. This illness was classified using algorithms. We suggest a Random Forest Classifier as the best model for PCOS Diagnosis based on patterns of menstrual cycle length with age, patterns of BMI, and number of folicles in this study. We are fitting a vanilla model as the Base Random Forest Model in this study in order to fit the final model.
"""